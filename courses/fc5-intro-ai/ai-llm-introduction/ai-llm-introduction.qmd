---
title: Introduction to LLM AI tools
subtitle: ""
---

::: {.unit-overview}
# Overview

This unit provides an introduction to the use of Large Language Model (LLM) based Artificial Intelligence (AI) tools (such as ChatGPT, Claude, Gemini) for coding and data analysis.

:::
<!-- end unit-overview div -->

::: {.unit-goals}
# Goals

- Be aware of possible ways to use AI to help with data analysis.
- Understand strengths, weaknesses and dangers of using AI.

:::
<!-- end unit-goals div -->

<!--
::: {.unit-video}
# Video, slides and audio transcript

Below is the video for this unit. Here are [the slides shown in the video](), and here is the [audio transcript](), as well as a [text version of the transcript]().

<iframe class="video" src="https://www.youtube.com/embed/VIDEO_ID" title="Introduction to current LLM AI tools" allowfullscreen></iframe>

:::
-->
<!-- end unit-video div -->


::: {.unit-reading}
# Reading

## Introduction

AI is a broad field, and there are different AI algorithms. You can potentially use some of them to analyze your data. We discussed this in a previous unit. The focus here is on AI tools that can help you in various coding and data analysis tasks.

Currently, the best tools for that are those based on Large Language Models (LLM). For simplicity, we are going to call them AI tools here, but be aware that there are other AI approaches out there. The focus is on using them to help with modeling and data science projects.



## LLM AI conceptual frameworks

AI, and especially generative AI like LLM are very new tools. Everyone is still trying to figure out how to use them, what they mean for the future, etc. While one can obviously use these tools without much further thought, it can be helpful to think about them in a conceptual way to have a potentially useful framework of interaction. Below are a few conceptual frameworks that I have heard from others or that I've been thinking about.


### AI as the intern/1st year graduate

This view comes up repeatedly. The idea is that you should think of LLM AI tools as being good at tasks that an intern, or a new worker could do without too much training. For example, asking an AI LLM tool to solve world hunger is not a good idea. However, asking it to give you a list of countries where malnutrition is the worst and a summary of likely reasons for that, is a task where it will probably produce a result that you can use as starting point for whatever your larger project is.

What that means is that to get the most out of the AI, you should break your tasks into manageable, well-prescribed bits, and ask the AI to tackle each one. The more details and instructions you provide, the more likely you will get something useful.


### The composer/conductor and the orchestra

Similar to the intern idea, one can think of the AI as a very versatile tool that can do many things, kinda like an orchestra. As a composer or conductor, you don't need to be able to play each instrument of the orchestra. But you do need to know enough about each instrument to compose meaningful instructions as to what everyone should play, and you should know what to expect, so when you tell the trumpets to play a certain tune, you should be able to assess if what they produce is what you have in mind, and correct as needed. 

I like this analogy because it not only describes the role of the AI, but also the role of the user. To use the AI effectively, you need to know enough about what it can do, and how to instruct it properly, to get useful output. You also need to be able to critically assess what the AI produces, and correct as needed.

Of course, this analogy goes beyond AI tools. We can say the same about other complex tools, for instance the `R` programming language or a car. You don't need to understand all the details of how these complex systems work under the hood (unless you want to become a full-time programmer or car mechanic), but you do need to know enough to give useful instructions, use them effectively, and critically assess what the machine returns and correct as needed.


### AI as a brainstorming partner

While AI is very good in doing specific, well-prescribed tasks, it can also be useful as a type of sparring partner or brainstorming device. You can throw ideas at the AI that are more open-ended, and ask it to provide its thoughts. Then you can iterate and that way possibly explore a topic and various options much faster than if you just thought about it yourself. This doesn't always lead to good results, but it's so quick and easy, it's often worth a try. Note that if you use AI in this way, you would interact with it differently compared to the above approach. To get specific work done, e.g. getting the AI to write you a piece of code, you want to be as specific and detailed as possible. You will often provide very long prompts. In contrast, if you use AI as brainstorming partner, you can have shorter, more vague prompts and do more of a back and forth. Just be clear what you are trying to accomplish and adjust your interactions accordingly.


### AI as electricity

It seems to me that long-term, AI is going to be a bit like electricity. It's going to be everywhere, it will power a lot of the environment around us, and it will become both more ubiquitous and possibly also more invisible. We use electricity all the time, and we rarely think about it. AI might become that way. We need to be prepared to have it be part of everything in the not-too-distance future.



## Tips for best practices

Here are some suggestions on how to use the LLM AI tools as efficiently as possible.

- Use them a lot. The more you use them, the better you will get at it, and the more you will understand what they can and cannot do.

- Think carefully about what exactly you want to the AI to accomplish and provide instructions that are as detailed and specific as possible. These days, this is often called **prompt engineering**.

- Iterate. Often the first version you get from the AI will not exactly what you want. You can try to ask the AI to rewrite/change/fix things. Or you can manually edit the code, which you can then use as input to ask the AI to make further changes.

- Try different tools. Performance between tools from competing companies, or even different AI models from the same company, can produce widely varying results. If one tool does not give you a satisfactory answer, try another one. 

- When you use AI to help with coding, ask the AI to add a lot of comments into the code to explain what each line of code does.

- Ask the AI to explain its reasoning, make it provide references, ask it to give specific examples. All of this helps you understand what the AI is doing, and helps you assess if the output makes sense.

- Break down big tasks into smaller tasks. Ask the AI to solve these smaller tasks individually and then pull things together.

- Cite as appropriate. If in doubt, include more information (e.g., prompts).




## Shortcomings and Dangers of AI Tools

For all its promises, the LLM AI tools continue to have shortcomings and there are dangers. The following topics are most relevant in the context of using AI tools to help with modeling and data science.


### Privacy/Confidentiality

When you use AI to help with data analysis, you might want to show your data to the AI and ask it to do something with it. The problem is that this could mean your data finds its way onto the servers of the company who's tool you are using. While many companies might have a version of an AI tool running that is not supposed to leak data, it's basically impossible for a regular end user to verify this. 

That means if you have data which is sensitive, e.g. human data, or data that you don't want to share, then you need to be careful when you decide if and how to let the AI have access to the data. A good solution is to generate synthetic data that has the structure of your real data but is made up. Then you can ask the AI to process this synthetic data and give you the code it generated. In a later step, you can go "offline" and use the code the AI helped you write on your real data. 

Beyond the data, it is important to keep in mind that if you have the AI running, it might access not just your current file but possibly also other sources you link to, e.g. other stuff on your computer. 

**In general, be careful what information you let the AI access and be aware that it might end up on the server of whatever company is running the AI tool.**


### Wrong answers

We are all aware of hallucinations, the tendency of AI tools to sometimes make up things and present wrong information in generally very convincing ways. It is always important to check the output you get from an AI tool. This is especially true when you use AI to help with data analysis. If the AI gives you code, make sure to understand what the code does, and check that it does what you want it to do. If the AI gives you text, check that the information is correct. If the AI gives you numbers, check that they make sense.

While non-working code created by an AI tool is annoying, it is easy to recognize. More dangerous is code that sees to work, and looks like it's doing the right thing, but has critical 

### Non-working code

While most of the AI tools have become pretty good at coding in R and other languages, at times they don't get it right. You might get code back that doesn't work. AI are known to **hallucinate**, i.e., make up stuff. For instance it's not uncommon that the AI invents an R command that does not exist. So when you get your code back, you will often need to do some trouble-shooting. At times, you can tell the AI that the code is not correct and ask it to fix it. If this doesn't always work, then you can make the fixes by hand or try to reformulate your request.

### Reproducibility

The companies making AI tools constantly update and improve the algorithms. Further, the underlying methods often have random components. This means that if you give the same instructions to an AI tool on different occasions, the results/code you get might differ. This means things might be non-reproducible.

While I encourage you to keep track of any input prompts you use to have the AI generate code, note that providing those prompts does not allow someone else (or future you) to exactly reproduce things. Thus, while AI tools can be useful helpers during the data analysis process, they should not be considered part of the final workflow, which instead should contain results/code (possibly generated with AI help) which can run in such a way to allow full reproducibility.

### Ethics of using AI

Here I'm not talking about the fact that most AI tools were trained on data without the permission of the original data generators, or that a lot of AI algorithms produce biased (unethical?) output. Those topics are too complex to tackle here. Instead, I'm talking about the ethics of using AI to help with your data analysis, or more generally your academic/professional work.

Since these tools are so new, nobody knows yet how to properly acknowledge AI help. I'm not sure either. If I search Google for an example to help with my code, and find something on StackOverflow that I use as basis for my code, should I cite it? I sometimes do add a link to the original post in my code. Partly to give credit, and partly to remind myself where I got it from. But I don't think there are clear rules on this.

Similarly, if you copy text from Wikipedia or some other source, you need to cite it. But if you read it, then repeat in your own words, when do you need to cite it? I don't think it's clear. This is similar with AI. If you have a full code or large chunk of text generated by AI and you use it "as is", you probably need to state that. But it's more likely that the AI will give you some parts of the code or text, and you write the rest. What is the rule for that? I don't think there are clear rules.

I suggest you follow the guideline of "if in doubt, cite/acknowledge". For instance, at the beginning of some code, you can make a statement saying "part of this code was generated by ChatPGT using the following prompt" and then state the prompt you use. Or if you use AI to help you interpret your data, you can state somewhere in your output (e.g., your Quarto document), that you used AI to help generate insights/text/etc. Providing this kind of information prevents you from being accused of "cheating" (if someone thinks using AI is cheating, for this course, you are encouraged to do so), and it also helps somewhat with the reproducibility (see above).



## Available AI tools

The field is changing rapidly. To keep up and have everything in one place [there is a separate unit that discusses different AI tools](../ai-tools/ai-tools.qmd)



:::
<!-- end unit-reading div -->


::: {.unit-summary}
# Summary

AI tools can be very useful tools to help you write code and do your data analysis. They are not perfect, but they can potentially save you a lot of time. I recommend you try them out and see if they can help you.

:::
<!-- end unit-summary div -->


::: {.unit-resources}
# Further Resources

See the [AI resource unit](../ai-resources/ai-resources.qmd). If you have other useful resources, I'd love to hear about them.

:::
<!-- end unit-resources div -->


::: {.unit-quiz}
# Test yourself

```{r ai-llm-introduction-quiz}
#| echo: false
#| results: "asis"
quizzes <- list("ai-llm-introduction-quiz-1.Rmd", "ai-llm-introduction-quiz-2.Rmd", "ai-llm-introduction-quiz-3.Rmd")
exams2forms::exams2forms(file = quizzes, title = 'ai-llm-introduction-quiz')
```
:::
<!-- end unit-quiz div -->



::: {.unit-exercise}
# Practice

* Draft one prompt that prioritizes privacy (synthetic data) and another that uses real data.
* Try the same task in two AI tools and note differences in output and reproducibility.
* Write a short acknowledgment sentence you could use when AI assistance was involved.

:::
<!-- end unit-exercise div -->
