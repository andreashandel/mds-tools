---
title: AI tools to analyze data
subtitle: ""
---

::: {.unit-overview}
# Overview

In this unit, we discuss ways you can use AI to analyze your data, aka fit models to it.

:::
<!-- end unit-overview div -->

::: {.unit-goals}
# Goals

- Be familiar with ways to fit models to data using AI.

:::
<!-- end unit-goals div -->

<!--
::: {.unit-video}
# Video, slides and audio transcript

Below is the video for this unit. Here are [the slides shown in the video](), and here is the [audio transcript](), as well as a [text version of the transcript]().

<iframe class="video" src="https://www.youtube.com/embed/VIDEO_ID" title="AI tools to analyze data" allowfullscreen></iframe>

:::
-->
<!-- end unit-video div -->


::: {.unit-reading}
# Reading

## Introduction


## Generating data and fitting it

I'm not sure if some of the problems with the code above would not show up if we used the - supposedly better - ChatGPT engine. We can try. Again, it's difficult to feed it data. We could try the copy and paste approach. But instead, I'm trying another approach. I'll give Bing the code that generates the data, then ask it to fit models to that generated data. Here is the prompt:

::: prompt
The code below produces a data frame called syn_dat2.
Take the data in that data frame and fit a linear model with drug concentration as predictor and cholesterol level as outcome.
Also fit a logistic model with drug concentration as predictor and adverse events as outcome.
For each model, provide model performance diagnostics.
Use the tidyverse packages for data manipulation tasks, and the tidymodels framework for model fitting.
For each function call, use explicit notation to specify from which R package the function comes from.
Add thorough documentation to your code so it's clear what each line of code does.

COPY AND PASTE [THIS CODE](synthetic-data-new-R-example-2-code.R) HERE
:::

I fed this to Microsoft Copilot in Precise mode. I also omitted the parts of the code after the data frame has been generated.

[This is what I got back](bing-analyze-example1.R). Again looks promising but doesn't work.
I then gave it this prompt:

::: prompt
The code does not work. Please fix it. Also, update it such that the actual R package from which a function comes from is called, not the tidymodels collection of packages.
:::

The result was code that used the standard `lm()` and `glm()` functions. While ok, that's not what I wanted, I still wanted `tidymodels` syntax, just not the `tidymodels::function` notation. So my next prompt was:

::: prompt
Change the code above such that instead of using the lm() and glm() functions, it uses the tidymodels set of functions
:::

[I ended up with this](bing-analyze-example2.R). It makes the same mistake as Claude, not properly turning the adverse event variable into a factor before trying to fit a logistic model. Some other bits also didn't fully work, but I didn't feel like fixing further.

I think you get the idea. Basically, the AI can produce quite useful bits of code that can speed up things, but it's rarely fully correct and you will always need to check it, and often at the end still manually intervene. I'm sure as time goes by, what you get on the first try will get increasingly better. Still, you need to know what exactly you want and understand if the output makes sense or not.

:::
<!-- end unit-reading div -->


::: {.unit-summary}
# Summary

I hope you can see how using AI tools to help with data analysis can potentially save a lot of time. Also, I think these examples make it quite clear: To be able to use those tools successfully, you need to know enough to understand what the AI should do, and if what it returns makes sense or not. If things don't run, there is an obvious error. But it is quite possible that the code runs but doesn't actually do the right thing. You only know this if you are familiar with what you want to accomplish. So while these AI tools can speed up coding a lot, they still require you to be an expert on whatever you are working on. Sorry! (Or maybe good, this means instead of not having a job in the near future, you'll likely just have a job that involves you being the master of AI tools, among other skills such as technical and subject matter expertise.)

:::
<!-- end unit-summary div -->


::: {.unit-resources}
# Further Resources

See the [AI resource unit](../ai-resources/ai-resources.qmd).

:::
<!-- end unit-resources div -->


::: {.unit-quiz}
# Test yourself

```{r ai-analysis-r-quiz}
#| echo: false
#| results: "asis"
quizzes <- list("ai-analysis-r-quiz-1.Rmd", "ai-analysis-r-quiz-2.Rmd", "ai-analysis-r-quiz-3.Rmd")
exams2forms::exams2forms(file = quizzes, title = 'ai-analysis-r-quiz')
```
:::
<!-- end unit-quiz div -->



::: {.unit-exercise}
# Practice

* Give an AI tool a clear modeling task on synthetic data and see whether the code runs.
* Check one model specification manually and fix any mismatched variable types.
* Ask the AI to add diagnostics and verify that they match what you expect.

:::
<!-- end unit-exercise div -->
